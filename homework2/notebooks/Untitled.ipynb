{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/mnist/2_semisupervised/train_x.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b67b41ff3262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mnist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2_semisupervised'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_x_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_x.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mvalid_x_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid_x.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtest_x_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_x.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neural-network-homework/.venv/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/mnist/2_semisupervised/train_x.npy'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = os.path.join('../data', 'mnist', '2_semisupervised')\n",
    "data_path = os.path.join('../data', 'mnist', '3_noisy')\n",
    "train_x_data = np.load(os.path.join(data_path, 'train_x.npy'))\n",
    "valid_x_data = np.load(os.path.join(data_path, 'valid_x.npy'))\n",
    "test_x_data = np.load(os.path.join(data_path, 'test_x.npy'))\n",
    "train_y_data = np.argmax(np.load(os.path.join(data_path, 'train_y.npy')), axis=1)\n",
    "valid_y_data = np.argmax(np.load(os.path.join(data_path, 'valid_y.npy')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = train_x_data\n",
    "y_data = train_y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[13 29 37  7 22  0  1  3  8  9]\n"
     ]
    }
   ],
   "source": [
    "unlabeled_x = []\n",
    "unlabeled_y = []\n",
    "labeled_x = []\n",
    "labeled_y = []\n",
    "labaled_data = []\n",
    "\n",
    "u, indices = np.unique(y_data, return_index=True)\n",
    "print(u)\n",
    "print(indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('../data', 'mnist', '2_semisupervised')\n",
    "# data_path = os.path.join('../data', 'mnist', '3_noisy')\n",
    "train_x_data = np.load(os.path.join(data_path, 'train_x.npy'))\n",
    "valid_x_data = np.load(os.path.join(data_path, 'valid_x.npy'))\n",
    "test_x_data = np.load(os.path.join(data_path, 'test_x.npy'))\n",
    "train_y_data = np.load(os.path.join(data_path, 'train_y.npy'))\n",
    "valid_y_data = np.argmax(np.load(os.path.join(data_path, 'valid_y.npy')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = train_x_data\n",
    "y_data = train_y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[3200  800]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "exists = y_data.sum(axis=1)\n",
    "u, counts = np.unique(exists, return_counts=True)\n",
    "print(u)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_x = x_data[np.where(exists==0)]\n",
    "unlabeled_y = y_data[np.where(exists==0)]\n",
    "labeled_x = x_data[np.where(exists==1)]\n",
    "labeled_y = y_data[np.where(exists==1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 784) (3200, 10) (800, 784) (800, 10)\n"
     ]
    }
   ],
   "source": [
    "print(unlabeled_x.shape, unlabeled_y.shape, labeled_x.shape, labeled_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('../data', 'mnist', '1_imbalanced')\n",
    "# data_path = os.path.join('../data', 'mnist', '3_noisy')\n",
    "train_x_data = np.load(os.path.join(data_path, 'train_x.npy'))\n",
    "train_y_data = np.load(os.path.join(data_path, 'train_y.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = train_x_data\n",
    "y_data = train_y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_y_data = np.argmax(y_data, axis=1)\n",
    "u, counts = np.unique(argmax_y_data, return_counts=True)\n",
    "max_count = max(counts)\n",
    "min_count = min(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-59-94e16f8332f7>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-59-94e16f8332f7>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    return x_data, y_data\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "if max_count == min_count:\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "num_of_data_for_fewer_classes = int((max_count / min_count)) - 1\n",
    "print(num_of_data_for_fewer_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, count in zip(u, counts):\n",
    "    if count != min_count:\n",
    "        continue\n",
    "    imbalanced_label_indexes = np.where(argmax_y_data == idx)\n",
    "    x_data = np.vstack((x_data, np.tile(x_data[imbalanced_label_indexes], (num_of_data_for_fewer_classes, 1))))\n",
    "    y_data = np.vstack((y_data, np.tile(y_data[imbalanced_label_indexes], (num_of_data_for_fewer_classes, 1))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 784)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 10)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([99])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty(1, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "one_hot(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-377253293ec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: one_hot(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "labels=np.array([1,2])\n",
    "torch.nn.functional.one_hot(labels, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 하이퍼 파라메터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/amazingguni/homework2\" target=\"_blank\">https://app.wandb.ai/amazingguni/homework2</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/amazingguni/homework2/runs/58x4e4rj\" target=\"_blank\">https://app.wandb.ai/amazingguni/homework2/runs/58x4e4rj</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.18 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "cuda is available: 0\n"
     ]
    }
   ],
   "source": [
    "from models.resnet import resnet18, resnet34\n",
    "from Answer import HomeworkDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n",
    "num_classes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('../data', 'mnist', '3_noisy')\n",
    "train_x_data = np.load(os.path.join(data_path, 'train_x.npy'))\n",
    "train_y_data = np.load(os.path.join(data_path, 'train_y.npy'))\n",
    "train_y_data = np.argmax(train_y_data, axis=1)\n",
    "train_dataset = HomeworkDataset(train_x_data, train_y_data, 'mnist', test_transforms)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=False)\n",
    "ckpt_path='../output/mnist/2_semisupervised/191204-1423/best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amazingguni/neural-network-homework/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "model = resnet18(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "pred_labels = np.array([], dtype=int)\n",
    "confidences = np.array([], dtype=int)\n",
    "for batch_data in train_loader:\n",
    "    images, labels = batch_data \n",
    "    images = Variable(images).to(device)\n",
    "    labels = Variable(labels).to(device)\n",
    "    outputs = model(images)\n",
    "    values, indices  = F.softmax(outputs, dim=None).max(axis=1)\n",
    "    pred_labels = np.hstack([pred_labels, indices.cpu()])\n",
    "    confidences = np.hstack([confidences, values.detach().cpu()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_path = '/home/amazingguni/images/mnist/3_noisy/train_real.csv'\n",
    "with open(train_real_path) as f:\n",
    "    real_labels = [int(line[:-1]) for line in f.readlines()]\n",
    "real_labels = np.array(real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3299/4000(82.475%)\n",
      "2591/2754(94.08133623819899%)\n"
     ]
    }
   ],
   "source": [
    "total = pred_labels.shape[0]\n",
    "correct = np.equal(pred_labels, real_labels).sum()\n",
    "ratio = float(correct)/float(total) * 100\n",
    "print(f'{correct}/{total}({ratio}%)')\n",
    "\n",
    "\n",
    "confidence_indice = np.where(confidences > 0.8)\n",
    "revised_pred_labels = pred_labels[confidence_indice]\n",
    "revised_real_labels = real_labels[confidence_indice]\n",
    "total = revised_pred_labels.shape[0]\n",
    "correct = np.equal(revised_pred_labels, revised_real_labels).sum()\n",
    "ratio = float(correct)/float(total) * 100\n",
    "print(f'{correct}/{total}({ratio}%)')\n",
    "# for pred, confidence, real in zip(pred_labels, pred_outputs_max, real_label):\n",
    "#     if pred != real:\n",
    "#         print(confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 하이퍼 파라메터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import numpy as np\n",
    "from models.resnet import resnet18, resnet34\n",
    "from Answer import HomeworkDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n",
    "num_classes = 100\n",
    "\n",
    "data_path = os.path.join('../data', 'cifar', '2_semisupervised')\n",
    "train_x_data = np.load(os.path.join(data_path, 'train_x.npy'))\n",
    "train_y_data = np.load(os.path.join(data_path, 'train_y.npy'))\n",
    "train_y_data = np.argmax(train_y_data, axis=1)\n",
    "train_dataset = HomeworkDataset(train_x_data, train_y_data, 'cifar', test_transforms)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=False)\n",
    "ckpt_path='../output/cifar/2_semisupervised/191204-1438/best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(1, 0), dtype=float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amazingguni/neural-network-homework/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23251,)\n",
      "[[0.54901963 0.5568628  0.5411765  ... 0.48235294 0.5568628  0.6862745 ]\n",
      " [0.44705883 0.44705883 0.5176471  ... 0.05098039 0.12941177 0.12941177]\n",
      " [0.7647059  0.63529414 0.52156866 ... 0.25882354 0.17254902 0.1254902 ]\n",
      " ...\n",
      " [0.88235295 0.93333334 0.9372549  ... 0.28235295 0.2901961  0.28627452]\n",
      " [0.3764706  0.6156863  0.5137255  ... 0.5803922  0.4862745  0.6392157 ]\n",
      " [0.84313726 0.72156864 0.7137255  ... 0.8509804  0.8509804  0.85490197]]\n",
      "[35 18 48 ... 25 34 91]\n"
     ]
    }
   ],
   "source": [
    "unlabeled_loader = train_loader\n",
    "unlabeled_x_data = train_x_data\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "model = resnet18(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "pred_labels = np.array([], dtype=int)\n",
    "confidences = np.array([], dtype=int)\n",
    "for batch_data in unlabeled_loader:\n",
    "    images, labels = batch_data \n",
    "    images = Variable(images).to(device)\n",
    "    outputs = model(images)\n",
    "    values, indices  = F.softmax(outputs, dim=None).max(axis=1)\n",
    "    pred_labels = np.hstack([pred_labels, indices.cpu()])\n",
    "    confidences = np.hstack([confidences, values.detach().cpu()])\n",
    "\n",
    "confidence_indice = np.where(confidences > 0.8)\n",
    "print(confidence_indice[0].shape)\n",
    "\n",
    "print(unlabeled_x_data[confidence_indice])\n",
    "print(pred_labels[confidence_indice])\n",
    "# train_x_data = np.concatenate((train_x_data, unlabeled_x_data), axis=0)\n",
    "# train_y_data = np.concatenate((train_y_data, total_pred), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amazingguni/neural-network-homework/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pred_labels = np.array([], dtype=int)\n",
    "confidences = np.array([], dtype=int)\n",
    "for batch_data in train_loader:\n",
    "    images, labels = batch_data \n",
    "    images = Variable(images).to(device)\n",
    "    labels = Variable(labels).to(device)\n",
    "    outputs = model(images)\n",
    "    values, indices  = F.softmax(outputs, dim=None).max(axis=1)\n",
    "    pred_labels = np.hstack([pred_labels, indices.cpu()])\n",
    "    confidences = np.hstack([confidences, values.detach().cpu()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_path = '/home/amazingguni/images/cifar/3_noisy/train_real.csv'\n",
    "with open(train_real_path) as f:\n",
    "    real_labels = [int(line[:-1]) for line in f.readlines()]\n",
    "real_labels = np.array(real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28530/40000(71.325%)\n",
      "23473/25676(91.42000311575012%)\n"
     ]
    }
   ],
   "source": [
    "total = pred_labels.shape[0]\n",
    "correct = np.equal(pred_labels, real_labels).sum()\n",
    "ratio = float(correct)/float(total) * 100\n",
    "print(f'{correct}/{total}({ratio}%)')\n",
    "\n",
    "\n",
    "\n",
    "confidence_indice = np.where(confidences > 0.8)\n",
    "revised_pred_labels = pred_labels[confidence_indice]\n",
    "revised_real_labels = real_labels[confidence_indice]\n",
    "total = revised_pred_labels.shape[0]\n",
    "correct = np.equal(revised_pred_labels, revised_real_labels).sum()\n",
    "ratio = float(correct)/float(total) * 100\n",
    "print(f'{correct}/{total}({ratio}%)')\n",
    "# for pred, confidence, real in zip(pred_labels, pred_outputs_max, real_label):\n",
    "#     if pred != real:\n",
    "#         print(confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar Noisy 정정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import numpy as np\n",
    "from models.resnet import resnet18, resnet34\n",
    "from Answer import HomeworkDataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n",
    "num_classes = 100\n",
    "\n",
    "data_path = os.path.join('../data', 'cifar', '3_noisy')\n",
    "train_x_data = np.load(os.path.join(data_path, 'train_x.npy'))\n",
    "train_y_data = np.load(os.path.join(data_path, 'train_y.npy'))\n",
    "train_y_data = np.argmax(train_y_data, axis=1)\n",
    "train_dataset = HomeworkDataset(train_x_data, train_y_data, 'cifar', test_transforms)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=False)\n",
    "ckpt_path='../output/cifar/3_noisy/191205-1239/best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amazingguni/neural-network-homework/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "loader = train_loader\n",
    "x_data = train_x_data\n",
    "y_data = train_y_data\n",
    "\n",
    "model = resnet18(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "pred_labels = np.array([], dtype=int)\n",
    "confidences = np.array([], dtype=int)\n",
    "for batch_data in loader:\n",
    "    images, labels = batch_data \n",
    "    images = Variable(images).to(device)\n",
    "    outputs = model(images)\n",
    "    values, indices  = F.softmax(outputs, dim=None).max(axis=1)\n",
    "    pred_labels = np.hstack([pred_labels, indices.cpu()])\n",
    "    confidences = np.hstack([confidences, values.detach().cpu()])\n",
    "\n",
    "\n",
    "\n",
    "# train_x_data = np.concatenate((train_x_data, unlabeled_x_data), axis=0)\n",
    "# train_y_data = np.concatenate((train_y_data, total_pred), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_path = '/home/amazingguni/images/cifar/3_noisy/train_real.csv'\n",
    "with open(train_real_path) as f:\n",
    "    real_labels = [int(line[:-1]) for line in f.readlines()]\n",
    "real_labels = np.array(real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin correct: 32067/40000(80.1675)\n",
      "pred correct: 22908/40000(57.269999999999996)\n",
      "pred_top correct: 9564/10062(95.05068574836017)\n",
      "revice correct: 33600/40000(84.0)\n"
     ]
    }
   ],
   "source": [
    "total = y_data.shape[0]\n",
    "y_correct = np.equal(real_labels, y_data).sum()\n",
    "print(f'origin correct: {y_correct}/{total}({float(y_correct)/float(total) * 100})')\n",
    "\n",
    "revice_y_correct = np.equal(real_labels, pred_labels).sum()\n",
    "print(f'pred correct: {revice_y_correct}/{total}({float(revice_y_correct)/float(total) * 100})')\n",
    "\n",
    "pred_top_indice = np.where(confidences > 0.99)\n",
    "pred_top = pred_labels[pred_top_indice]\n",
    "pred_top_total = pred_top.shape[0]\n",
    "pred_top_correct = np.equal(real_labels[pred_top_indice], pred_top).sum()\n",
    "print(f'pred_top correct: {pred_top_correct}/{pred_top_total}({float(pred_top_correct)/float(pred_top_total) * 100})')\n",
    "\n",
    "revice_y = np.where(confidences > 0.98, pred_labels, y_data)\n",
    "revice_y_correct = np.equal(real_labels, revice_y).sum()\n",
    "print(f'revice correct: {revice_y_correct}/{total}({float(revice_y_correct)/float(total) * 100})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Noisy 정정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import numpy as np\n",
    "from models.resnet import resnet18, resnet34\n",
    "from Answer import HomeworkDataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n",
    "num_classes = 10\n",
    "\n",
    "data_path = os.path.join('../data', 'mnist', '3_noisy')\n",
    "train_x_data = np.load(os.path.join(data_path, 'train_x.npy'))\n",
    "train_y_data = np.load(os.path.join(data_path, 'train_y.npy'))\n",
    "train_y_data = np.argmax(train_y_data, axis=1)\n",
    "train_dataset = HomeworkDataset(train_x_data, train_y_data, 'mnist', test_transforms)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=False)\n",
    "ckpt_path='../output/mnist/3_noisy/191205-1240/best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amazingguni/neural-network-homework/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "loader = train_loader\n",
    "x_data = train_x_data\n",
    "y_data = train_y_data\n",
    "\n",
    "model = resnet18(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "pred_labels = np.array([], dtype=int)\n",
    "confidences = np.array([], dtype=int)\n",
    "for batch_data in loader:\n",
    "    images, labels = batch_data \n",
    "    images = Variable(images).to(device)\n",
    "    outputs = model(images)\n",
    "    values, indices  = F.softmax(outputs, dim=None).max(axis=1)\n",
    "    pred_labels = np.hstack([pred_labels, indices.cpu()])\n",
    "    confidences = np.hstack([confidences, values.detach().cpu()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_path = '/home/amazingguni/images/mnist/3_noisy/train_real.csv'\n",
    "with open(train_real_path) as f:\n",
    "    real_labels = [int(line[:-1]) for line in f.readlines()]\n",
    "real_labels = np.array(real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin correct: 3272/4000(81.8)\n",
      "pred correct: 3418/4000(85.45)\n",
      "pred_top correct: 2715/2854(95.12964260686756)\n",
      "revice correct: 3672/4000(91.8)\n"
     ]
    }
   ],
   "source": [
    "total = y_data.shape[0]\n",
    "y_correct = np.equal(real_labels, y_data).sum()\n",
    "print(f'origin correct: {y_correct}/{total}({float(y_correct)/float(total) * 100})')\n",
    "\n",
    "revice_y_correct = np.equal(real_labels, pred_labels).sum()\n",
    "print(f'pred correct: {revice_y_correct}/{total}({float(revice_y_correct)/float(total) * 100})')\n",
    "\n",
    "pred_top_indice = np.where(confidences > 0.95)\n",
    "pred_top = pred_labels[pred_top_indice]\n",
    "pred_top_total = pred_top.shape[0]\n",
    "pred_top_correct = np.equal(real_labels[pred_top_indice], pred_top).sum()\n",
    "print(f'pred_top correct: {pred_top_correct}/{pred_top_total}({float(pred_top_correct)/float(pred_top_total) * 100})')\n",
    "\n",
    "revice_y = np.where(confidences > 0.98, pred_labels, y_data)\n",
    "revice_y_correct = np.equal(real_labels, revice_y).sum()\n",
    "print(f'revice correct: {revice_y_correct}/{total}({float(revice_y_correct)/float(total) * 100})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
